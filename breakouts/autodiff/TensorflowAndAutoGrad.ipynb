{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(np.array([3.]))\n",
    "y = x ** 4 + x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 3.] [ 90.]\n",
      "20 [ 0.07725829] [ 0.00600447]\n",
      "40 [ 0.00932879] [  8.70338876e-05]\n",
      "60 [ 0.00113405] [  1.28606939e-06]\n",
      "80 [ 0.00013787] [  1.90091594e-08]\n",
      "100 [  1.67622231e-05] [  2.80972124e-10]\n",
      "120 [  2.03789494e-06] [  4.15301579e-12]\n",
      "140 [  2.47760441e-07] [  6.13852362e-14]\n",
      "160 [  3.01218846e-08] [  9.07327931e-16]\n",
      "180 [  3.66211784e-09] [  1.34111070e-17]\n",
      "200 [  4.45228021e-10] [  1.98227990e-19]\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.05)\n",
    "train = optimizer.minimize(y)\n",
    "\n",
    "# Before starting, initialize the variables.  We will 'run' this first.\n",
    "init = tf.initialize_all_variables()\n",
    "# Launch the graph.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Fit the line.\n",
    "    for step in range(201):\n",
    "        if step % 20 == 0:\n",
    "            print(step, sess.run(x), sess.run(y))\n",
    "        sess.run(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import autograd\n",
    "from autograd import numpy as anp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = anp.array([3], dtype='f8')\n",
    "def y(x):\n",
    "    return x **4 + x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(autograd.grad(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 1.902044886389921e-18\n",
      " hess_inv: array([[ 0.49997778]])\n",
      "      jac: array([ -2.75829287e-09])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 12\n",
      "      nit: 9\n",
      "     njev: 12\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ -1.37914643e-09])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/projectdirs/m779/yfeng1/envs/tensorflow/lib/python3.5/site-packages/scipy/optimize/_minimize.py:385: RuntimeWarning: Method BFGS does not use Hessian information (hess).\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "r = minimize(y, x, jac=autograd.grad(y), hess=autograd.hessian(y))\n",
    "print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
